## [Training Deep Networks with Synthetic Data: Bridging the Reality Gap by Domain Randomization](https://arxiv.org/abs/1804.06516)

A system for training deep neural networks for object detection using synthetic images.

### Notes
1. Domain randomization (DR) is an approach that randomly perturbs the environment in non-photorealistic ways to force the network to learn to focus on the essential features of the image. This paper extends DR to the task of real-world object detection. This paper addresses several questions:
   - Can DR on synthetic data achieve compelling results on real-world data?
   - Can augmentation of DR with real data improve accuracy?
   - How do the parameters of DR affect results?
   - How does DR compare to higher quality/more expensive synthetic datasets?
2. Domain randomization:
   - 3D models of objects are placed in a 3D scene at random positions and orientations.
   - Flying distractors, or random geometric shapes, are added to better enable the network to learn to ignore irrelevant objects in the scene.
   - A random number of lights are added, and the scene is rendered from a random camera viewpoint, after which the result is composed over a random background image.
   - Advantage over other virtual datasets: orders of magnitude faster to create, and include variations that force the network to focus on pertinent parts of the images.
3. For evaluation, a deep neural network (DNN) for object detection is trained on the image dataset generated by DR and compared against another trained on a virtual dataset. Testing of both networks is done on the real dataset.
   - Three state-of-the-art network architectures are used: Faster R-CNN, R-FCN, and SSD.
   - Results show that Faster R-CNN trained on the virtual dataset scored higher, while the other methods achieved higher score with the dataset generated by DR, despite the fact that the virtual dataset is closely correlated with the real dataset.
   - On high values of recall, DR consistently achieves lower precision than the virtual dataset, possibly due to a mismatch between generated and real data. This points to using fine-tuning on real images.
   - Augmenting the DR generated dataset with real data resulted in a better performance compared to the virtual dataset.
4. An ablation study is conducted to compare the effects of the individual DR parameters. The results show that using all the components of DR resulted in the highest performance.
5. Several experiments are conducted with respect to training strategies:
   - For pretraining, the performance of the networks are tested after initializing on the COCO dataset. Despite the difference in datasets, training on the DR generated dataset resulted in the best performance, showing potential to overcome gaps between different datasets.
   - Results show that freezing the weights of the feature extraction layers degrade performance.
   - Results show that pretraining significantly helps performance.

### Thoughts
1. This paper demonstrates that relying solely on synthetic data can still achieve good performance on a complex task like object detection. This is especially impressive considering how much less work it takes to generate the synthetic data, compared to collecting real-world data or manually generating virtual data.
2. It surprised me that even without fine-tuning on the real-world data the network that is solely trained on the DR generated synthetic dataset is able to perform well. This is probably due to the amount of variation that the generated images capture.
