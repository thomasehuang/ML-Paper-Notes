## [Pedestrian-Synthesis-GAN: Generating Pedestrian Data in Real Scene and Beyond](https://arxiv.org/abs/1804.02047)

A GAN-based model with multiple discriminators for synthesizing pedestrians. \[[code](https://github.com/yueruchen/Pedestrian-Synthesis-GAN)\]

### Notes
1. This paper proposes a GAN-based model to generate realistic pedestrian images in real scene and utilize them as the augmented data to train the CNN-based pedestrian detector. It uses two discriminators, one for learning background context and another for classifying pedestrians. The first leads to a smooth connection between the background and the synthetic pedestrian. The latter makes the generator generate pedestrians with more realistic shape and details. A Spatial Pyramid Pooling (SPP) layer is used to avoid the effect of resizing.
2. Architecture:
   - The generator is based on U-Net, an encoder-decoder network with symmetric skip connections.
   - The discriminator for pedestrians learns to distinguish between synthetic pedestrians and real pedestrians. A SPP layer is employed to deal with varying sizes of pedestrians.
   - The discriminator for background context learns to classify between real and synthesized pairs, which is composed of the noise image concatenated with either the ground truth image or the generated image. The main structure follows that of DCGAN, with several modifications.
3. The loss function is composed of several components:
   - For the background context discriminator, the LSGAN loss is used (least square loss).
   - For the pedestrian discriminator, a negative log likelihood objective is used.
   - The traditional l1 loss is applied to control the differences between the generated image and ground truth image.
4. Experiments are conducted on the Cityscapes dataset:
   - Two qualitative experiments are done: 1. generating pedestrians on the positions of real pedestrians, and 2. generating pedestrians on background images without pedestrians. Compared with the Pix2Pix baseline, the results of PS-GAN looks much better in quality. Models with the same structure but several components changed are also compared to the proposed model, showing the importance of the components in the final model.
   - Data generated by PS-GAN is used to train a Faster R-CNN detector, and it is compared with a baseline detector trained solely on the original images and another trained on data sythesized by Pix2Pix.
     - The detector trained on PS-GAN generated data achieved better performance. It is observed that adding too many synthetic data downgrades the performance, since the normal data distribution is destroyed.
     - Even when Faster R-CNN is trained in a more saturated state (more real training data), the model with data augmentation can achieve a higher performance.
5. PS-GAN is also applied to the Tsinghua-Daimler Cyclist Benchmark (TDCB) dataset for cyclist detection.
   - The model trained on Cityscapes is used to generate pedestrians on empty background images from the TDCB dataset. Even without training on the TDCB dataset, PS-GAN is able to generate high-quality and realistic images.
   - The same experiment as with Cityscapes for training the Faster R-CNN detector is conducted. The results show that adding synthetic data resulted in better performance.
6. Detectors pretrained on real images is used to detect the synthetic samples, and the performance is compared between the samples generated by Pix2Pix and Ps-GAN. The performance of the detectors on the PS-GAN generated samples significantly outperforms those on the Pix2Pix generated data.

### Thoughts
1. It will be interesting to see if the synthesized data improves performance on other tasks like segmentation.
